{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "name": "advanced.ipynb",
      "provenance": [],
      "collapsed_sections": [],
      "toc_visible": true
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "rX8mhOLljYeM"
      },
      "source": [
        "##### Copyright 2019 The TensorFlow Authors."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "cellView": "form",
        "id": "BZSlp3DAjdYf"
      },
      "source": [
        "#@title Licensed under the Apache License, Version 2.0 (the \"License\");\n",
        "# you may not use this file except in compliance with the License.\n",
        "# You may obtain a copy of the License at\n",
        "#\n",
        "# https://www.apache.org/licenses/LICENSE-2.0\n",
        "#\n",
        "# Unless required by applicable law or agreed to in writing, software\n",
        "# distributed under the License is distributed on an \"AS IS\" BASIS,\n",
        "# WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n",
        "# See the License for the specific language governing permissions and\n",
        "# limitations under the License."
      ],
      "execution_count": 2,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "3wF5wszaj97Y"
      },
      "source": [
        "# TensorFlow 2 quickstart for experts"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "DUNzJc4jTj6G"
      },
      "source": [
        "<table class=\"tfo-notebook-buttons\" align=\"left\">\n",
        "  <td>\n",
        "    <a target=\"_blank\" href=\"https://www.tensorflow.org/tutorials/quickstart/advanced\"><img src=\"https://www.tensorflow.org/images/tf_logo_32px.png\" />View on TensorFlow.org</a>\n",
        "  </td>\n",
        "  <td>\n",
        "    <a target=\"_blank\" href=\"https://colab.research.google.com/github/tensorflow/docs/blob/master/site/en/tutorials/quickstart/advanced.ipynb\"><img src=\"https://www.tensorflow.org/images/colab_logo_32px.png\" />Run in Google Colab</a>\n",
        "  </td>\n",
        "  <td>\n",
        "    <a target=\"_blank\" href=\"https://github.com/tensorflow/docs/blob/master/site/en/tutorials/quickstart/advanced.ipynb\"><img src=\"https://www.tensorflow.org/images/GitHub-Mark-32px.png\" />View source on GitHub</a>\n",
        "  </td>\n",
        "  <td>\n",
        "    <a href=\"https://storage.googleapis.com/tensorflow_docs/docs/site/en/tutorials/quickstart/advanced.ipynb\"><img src=\"https://www.tensorflow.org/images/download_logo_32px.png\" />Download notebook</a>\n",
        "  </td>\n",
        "</table>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "hiH7AC-NTniF"
      },
      "source": [
        "This is a [Google Colaboratory](https://colab.research.google.com/notebooks/welcome.ipynb) notebook file. Python programs are run directly in the browser—a great way to learn and use TensorFlow. To follow this tutorial, run the notebook in Google Colab by clicking the button at the top of this page.\n",
        "\n",
        "1. In Colab, connect to a Python runtime: At the top-right of the menu bar, select *CONNECT*.\n",
        "2. Run all the notebook code cells: Select *Runtime* > *Run all*."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "eOsVdx6GGHmU"
      },
      "source": [
        "Download and install TensorFlow 2. Import TensorFlow into your program:\n",
        "\n",
        "Note: Upgrade `pip` to install the TensorFlow 2 package. See the [install guide](https://www.tensorflow.org/install) for details."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "QS7DDTiZGRTo"
      },
      "source": [
        "Import TensorFlow into your program:"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "0trJmd6DjqBZ"
      },
      "source": [
        "import tensorflow as tf\n",
        "\n",
        "from tensorflow.keras.layers import Dense, Flatten, Conv2D\n",
        "from tensorflow.keras import Model"
      ],
      "execution_count": 3,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "7NAbSZiaoJ4z"
      },
      "source": [
        "Load and prepare the [MNIST dataset](http://yann.lecun.com/exdb/mnist/)."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "JqFRS6K07jJs",
        "outputId": "37a068eb-9197-4288-87be-ac1f82c01d0f",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "source": [
        "mnist = tf.keras.datasets.mnist\n",
        "\n",
        "(x_train, y_train), (x_test, y_test) = mnist.load_data()\n",
        "x_train, x_test = x_train / 255.0, x_test / 255.0\n",
        "\n",
        "# Add a channels dimension\n",
        "\n",
        "# > tf.newaxis same as expand_dims but different syntax\n",
        "\n",
        "print(tf.expand_dims(x_train, axis=-1).shape)\n",
        "\n",
        "x_train = x_train[..., tf.newaxis].astype(\"float32\")\n",
        "x_test = x_test[..., tf.newaxis].astype(\"float32\")\n",
        "\n",
        "print(x_train.shape)"
      ],
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Downloading data from https://storage.googleapis.com/tensorflow/tf-keras-datasets/mnist.npz\n",
            "11493376/11490434 [==============================] - 0s 0us/step\n",
            "(60000, 28, 28, 1)\n",
            "(60000, 28, 28, 1)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "k1Evqx0S22r_"
      },
      "source": [
        "Use `tf.data` to batch and shuffle the dataset:"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "8Iu_quO024c2"
      },
      "source": [
        "# tf.data.Dataset deals with formatting of datasets\n",
        "# from_tensor_slices returns individual tensors for each row (vs from_tensors returning just one tensor, & hence one more dim)\n",
        "\n",
        "# Shuffle will create a random buffer from which elements are chosen\n",
        "# In this case it creates a buffer of the first 10,000 elements among which one is then randomly chosen\n",
        "  # > Then the buffer size decreases by one and it takes the 10,001th element added to the 10,000 buffer\n",
        "  # > Hence the first element it outputs is forced to be in the first 10,000\n",
        "  # For perfect shuffling buffer size must >= dataset size (60K for us), but this is more expensive\n",
        "train_ds = tf.data.Dataset.from_tensor_slices(\n",
        "    (x_train, y_train)).shuffle(10000).batch(32)\n",
        "\n",
        "test_ds = tf.data.Dataset.from_tensor_slices((x_test, y_test)).batch(32)"
      ],
      "execution_count": 5,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "yk3naT_S2sTl",
        "outputId": "cfded3d9-af35-4359-8a49-10c7da1bd316",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "source": [
        "# 60000 / 32\r\n",
        "print(len(train_ds))"
      ],
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "1875\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "lIWrHq2B05Bd",
        "outputId": "26800058-4d78-4b75-87e2-52a24fcb03ec",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "source": [
        "# You can then iterate through it\r\n",
        "for dict_slice, target in train_ds:\r\n",
        "     print(dict_slice.shape, target.shape)\r\n",
        "     break\r\n",
        "\r\n",
        "# take > create new dataset with less datapoints\r\n",
        "for dict_slice, target in train_ds.take(1):\r\n",
        "     print(dict_slice.shape, target.shape)"
      ],
      "execution_count": 7,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "(32, 28, 28, 1) (32,)\n",
            "(32, 28, 28, 1) (32,)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "BPZ68wASog_I"
      },
      "source": [
        "Build the `tf.keras` model using the Keras [model subclassing API](https://www.tensorflow.org/guide/keras#model_subclassing):"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "fugjCjNE7pm5"
      },
      "source": [
        "$$Out = ((W−F+2P)/S)+1$$\r\n",
        "\r\n",
        "$$26 = ((28−3+2 * 0)/1)+1$$"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "h3IKyzTCDNGo"
      },
      "source": [
        "\n",
        "class MyModel(Model):\n",
        "  def __init__(self):\n",
        "    super(MyModel, self).__init__()\n",
        "\n",
        "    # In Torch: self.conv = nn.Conv2d(1, 32, kernel_size=3) > 1 in_channel (for rgb image in_channel will be 3), 32 out channels\n",
        "    # > For 28x28 images, outputs (BS, 32, 26, 26)\n",
        "    # Padding is a string for TF of valid or same; but int for Torch\n",
        "    # Above torch code is in TF: \n",
        "    self.conv1 = Conv2D(32, 3, activation='relu') # 32 filters, 3 kernel size\n",
        "\n",
        "    self.flatten = Flatten() # > (BS, 32*26*26)\n",
        "    self.d1 = Dense(128, activation='relu') # > Output: (BS, 128)\n",
        "    self.d2 = Dense(10) # > No activation; > Output: (BS, 10)\n",
        "\n",
        "  def call(self, x):\n",
        "    x = self.conv1(x)\n",
        "    x = self.flatten(x)\n",
        "    x = self.d1(x)\n",
        "    return self.d2(x)\n",
        "\n",
        "# Create an instance of the model\n",
        "model = MyModel()"
      ],
      "execution_count": 8,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "uGih-c2LgbJu"
      },
      "source": [
        "Choose an optimizer and loss function for training: "
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "u48C9WQ774n4"
      },
      "source": [
        "loss_object = tf.keras.losses.SparseCategoricalCrossentropy(from_logits=True)\n",
        "\n",
        "optimizer = tf.keras.optimizers.Adam()"
      ],
      "execution_count": 9,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "JB6A1vcigsIe"
      },
      "source": [
        "Select metrics to measure the loss and the accuracy of the model. These metrics accumulate the values over epochs and then print the overall result."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "N0MqHFb4F_qn"
      },
      "source": [
        "train_loss = tf.keras.metrics.Mean(name='train_loss')\n",
        "train_accuracy = tf.keras.metrics.SparseCategoricalAccuracy(name='train_accuracy')\n",
        "\n",
        "test_loss = tf.keras.metrics.Mean(name='test_loss')\n",
        "test_accuracy = tf.keras.metrics.SparseCategoricalAccuracy(name='test_accuracy')"
      ],
      "execution_count": 10,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ix4mEL65on-w"
      },
      "source": [
        "Use `tf.GradientTape` to train the model:"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "9SVzv2vj-dYD"
      },
      "source": [
        "## Eager vs Lazy Execution // Dynamic vs Static Comp. Graphs\r\n",
        "\r\n",
        "\r\n",
        "Originally, Torch was Dynamic Comp. Geaphs & TF only static. Dynamic allows changing the input while running & is more flexible, python native. It makes debugging also a whole lot easier. Static means you need to define placeholders for everything expected to happen. It may be much less code for simpler symmetric models and provide accelerations not possible for dynamic graphs. <br>\r\n",
        "With TF 2.0, there is now support for dynamic ocmp. graphs in TF. \r\n",
        "<br> <br>\r\n",
        "\r\n",
        "### @tf.function\r\n",
        "\r\n",
        "Introduced in TF2.0 for dynamic computation. It turns a function into a graph. You can do so by adding the decorator or calling it directly, via function_that_uses_graph = tf.function(callable_func).\r\n",
        "\r\n",
        "Once the function is called the first time it will be traced, i.e. via tf.autograph it is turned into a computation graph.\r\n",
        "\r\n",
        "#### Pecularities\r\n",
        "\r\n",
        "Python code gets only executed once, as it constructs a tf graph > Use tf.print instead of print.\r\n",
        "\r\n",
        "\r\n",
        "https://stackoverflow.com/questions/46154189/what-is-the-difference-of-static-computational-graphs-in-tensorflow-and-dynamic\r\n",
        "https://www.machinelearningplus.com/deep-learning/how-use-tf-function-to-speed-up-python-code-tensorflow/#:~:text=Google%20Bookmarks%20Share-,tf.,to%20create%20portable%20Tensorflow%20models.\r\n",
        "\r\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "OZACiVqA8KQV"
      },
      "source": [
        "# @tf.function converts python code to callable TF Graph function\n",
        "\n",
        "# tf.GradientTape() is needed for eager mode to record parts for differentiation\n",
        "\n",
        "@tf.function\n",
        "def train_step(images, labels):\n",
        "  with tf.GradientTape() as tape:\n",
        "    # training=True is only needed if there are layers with different\n",
        "    # behavior during training versus inference (e.g. Dropout).\n",
        "    predictions = model(images, training=True)\n",
        "    loss = loss_object(labels, predictions)\n",
        "  gradients = tape.gradient(loss, model.trainable_variables)\n",
        "  optimizer.apply_gradients(zip(gradients, model.trainable_variables))\n",
        "\n",
        "  # Equivalent of the above 4 lines of code in torch:\n",
        "  #loss = compute_loss(model, x)\n",
        "  #optimizer.zero_grad()\n",
        "  #loss.backward()\n",
        "  #optimizer.step()\n",
        "\n",
        "  train_loss(loss)\n",
        "  train_accuracy(labels, predictions)"
      ],
      "execution_count": 12,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Z8YT7UmFgpjV"
      },
      "source": [
        "Test the model:"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "xIKdEzHAJGt7"
      },
      "source": [
        "@tf.function\n",
        "def test_step(images, labels):\n",
        "  # training=False is only needed if there are layers with different\n",
        "  # behavior during training versus inference (e.g. Dropout).\n",
        "\n",
        "  # No gradient tape here as we do not want to save gradients; It's like with torch.no_grad() but the other way round\n",
        "  predictions = model(images, training=False)\n",
        "  t_loss = loss_object(labels, predictions)\n",
        "\n",
        "  test_loss(t_loss)\n",
        "  test_accuracy(labels, predictions)\n",
        "\n",
        "\n",
        "  "
      ],
      "execution_count": 13,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "i-2pkctU_Ci7",
        "outputId": "fe8fda52-6316-4a22-e724-e2e995ce70e3",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "source": [
        "EPOCHS = 5\n",
        "\n",
        "for epoch in range(EPOCHS):\n",
        "  # Reset the metrics at the start of the next epoch\n",
        "  train_loss.reset_states()\n",
        "  train_accuracy.reset_states()\n",
        "  test_loss.reset_states()\n",
        "  test_accuracy.reset_states()\n",
        "\n",
        "  for images, labels in train_ds:\n",
        "    train_step(images, labels)\n",
        "\n",
        "  for test_images, test_labels in test_ds:\n",
        "    test_step(test_images, test_labels)\n",
        "\n",
        "  print(\n",
        "    f'Epoch {epoch + 1}, '\n",
        "    f'Loss: {train_loss.result()}, '\n",
        "    f'Accuracy: {train_accuracy.result() * 100}, '\n",
        "    f'Test Loss: {test_loss.result()}, '\n",
        "    f'Test Accuracy: {test_accuracy.result() * 100}'\n",
        "  )"
      ],
      "execution_count": 14,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Epoch 1, Loss: 0.13406850397586823, Accuracy: 95.97166442871094, Test Loss: 0.059919048100709915, Test Accuracy: 98.00999450683594\n",
            "Epoch 2, Loss: 0.042148616164922714, Accuracy: 98.69166564941406, Test Loss: 0.0505760982632637, Test Accuracy: 98.43000030517578\n",
            "Epoch 3, Loss: 0.021483521908521652, Accuracy: 99.27832794189453, Test Loss: 0.06270965188741684, Test Accuracy: 98.20999908447266\n",
            "Epoch 4, Loss: 0.013704432174563408, Accuracy: 99.57666015625, Test Loss: 0.053873177617788315, Test Accuracy: 98.50999450683594\n",
            "Epoch 5, Loss: 0.009670468047261238, Accuracy: 99.67832946777344, Test Loss: 0.06497903913259506, Test Accuracy: 98.33999633789062\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "T4JfEh7kvx6m"
      },
      "source": [
        "The image classifier is now trained to ~98% accuracy on this dataset. To learn more, read the [TensorFlow tutorials](https://www.tensorflow.org/tutorials)."
      ]
    }
  ]
}