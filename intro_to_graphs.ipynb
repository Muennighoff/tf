{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "intro_to_graphs.ipynb",
      "provenance": [],
      "collapsed_sections": [],
      "toc_visible": true
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "N7ITxKLUkX0v"
      },
      "source": [
        "##### Copyright 2020 The TensorFlow Authors."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "cellView": "form",
        "id": "yOYx6tzSnWQ3"
      },
      "source": [
        "#@title Licensed under the Apache License, Version 2.0 (the \"License\");\n",
        "# you may not use this file except in compliance with the License.\n",
        "# You may obtain a copy of the License at\n",
        "#\n",
        "# https://www.apache.org/licenses/LICENSE-2.0\n",
        "#\n",
        "# Unless required by applicable law or agreed to in writing, software\n",
        "# distributed under the License is distributed on an \"AS IS\" BASIS,\n",
        "# WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n",
        "# See the License for the specific language governing permissions and\n",
        "# limitations under the License."
      ],
      "execution_count": 1,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "6xgB0Oz5eGSQ"
      },
      "source": [
        "# Introduction to graphs and tf.functions"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "w4zzZVZtQb1w"
      },
      "source": [
        "<table class=\"tfo-notebook-buttons\" align=\"left\">\n",
        "  <td>\n",
        "    <a target=\"_blank\" href=\"https://www.tensorflow.org/guide/intro_to_graphs\"><img src=\"https://www.tensorflow.org/images/tf_logo_32px.png\" />View on TensorFlow.org</a>\n",
        "  </td>\n",
        "  <td>\n",
        "    <a target=\"_blank\" href=\"https://colab.research.google.com/github/tensorflow/docs/blob/master/site/en/guide/intro_to_graphs.ipynb\"><img src=\"https://www.tensorflow.org/images/colab_logo_32px.png\" />Run in Google Colab</a>\n",
        "  </td>\n",
        "  <td>\n",
        "    <a target=\"_blank\" href=\"https://github.com/tensorflow/docs/blob/master/site/en/guide/intro_to_graphs.ipynb\"><img src=\"https://www.tensorflow.org/images/GitHub-Mark-32px.png\" />View source on GitHub</a>\n",
        "  </td>\n",
        "  <td>\n",
        "    <a href=\"https://storage.googleapis.com/tensorflow_docs/docs/site/en/guide/intro_to_graphs.ipynb\"><img src=\"https://www.tensorflow.org/images/download_logo_32px.png\" />Download notebook</a>\n",
        "  </td>\n",
        "</table>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "RBKqnXI9GOax"
      },
      "source": [
        "## Overview \n",
        "This guide goes beneath the surface of TensorFlow and Keras to see how TensorFlow works.  If you instead want to immediately get started with Keras, please see [our collection of Keras guides](keras/).\n",
        "\n",
        "In this guide you'll see the core of how TensorFlow allows you to make simple changes to your code to get graphs, and how they are stored and represented, and how you can use them to accelerate and export your models.\n",
        "\n",
        "Note: For those of you who are only familiar with TensorFlow 1.x, this guide demonstrates a very different view of graphs.\n",
        "\n",
        "This is a short-form introduction; for a full introduction to these concepts, see [the `tf.function` guide](function).\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "v0DdlfacAdTZ"
      },
      "source": [
        "### What are graphs?\n",
        "\n",
        "In the previous three guides, you have seen TensorFlow running **eagerly**.  This means TensorFlow operations are executed by Python, operation by operation, and returning results back to Python. Eager TensorFlow takes advantage of GPUs, allowing you to place variables, tensors, and even operations on GPUs and TPUs.  It is also easy to debug.\n",
        "\n",
        "For some users, you may never need or want to leave Python.\n",
        "\n",
        "However, running TensorFlow op-by-op in Python prevents a host of accelerations otherwise available. If you can extract tensor computations from Python, you can make them into a *graph*.  \n",
        "\n",
        "**Graphs are data structures that contain a set of `tf.Operation` objects, which represent units of computation; and `tf.Tensor` objects, which represent the units of data that flow between operations.** They are defined in a `tf.Graph` context. Since these graphs are data structures, they can be saved, run, and restored all without the original Python code.\n",
        "\n",
        "This is what a simple two-layer graph looks like when visualized in TensorBoard.\n",
        "\n",
        ">>> Two-layer because two Dense layers (matmul is the weight dot & add is the bias)\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "FvQ5aBuRGT1o"
      },
      "source": [
        "![a two-layer tensorflow graph](\t\n",
        "https://storage.cloud.google.com/tensorflow.org/images/two-layer-network.png)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "DHpY3avXGITP"
      },
      "source": [
        "### The benefits of graphs\n",
        "\n",
        "With a graph, you have a great deal of flexibility.  You can use your TensorFlow graph in environments that don't have a Python interpreter, like mobile applications, embedded devices, and backend servers.  TensorFlow uses graphs as the format for saved models when it exports them from Python.\n",
        "\n",
        "Graphs are also easily optimized, allowing the compiler to do transformations like:\n",
        "\n",
        "* Statically infer the value of tensors by folding constant nodes in your computation *(\"constant folding\")*.\n",
        "* Separate sub-parts of a computation that are independent and split them between threads or devices.\n",
        "* Simplify arithmetic operations by eliminating common subexpressions.\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "o1x1EOD9GjnB"
      },
      "source": [
        "There is an entire optimization system, [Grappler](./graph_optimization.ipynb), to perform this and other speedups.\n",
        "\n",
        "In short, graphs are extremely useful and let your TensorFlow run **fast**, run **in parallel**, and run efficiently **on multiple devices**.\n",
        "\n",
        "However, you still want to define our machine learning models (or other computations) in Python for convenience, and then automatically construct graphs when you need them."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "pSZebVuWxDXu"
      },
      "source": [
        "## Tracing graphs\n",
        "\n",
        "The way you create a graph in TensorFlow is to use `tf.function`, either as a direct call or as a decorator."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "goZwOXp_xyQj"
      },
      "source": [
        "import tensorflow as tf\n",
        "import timeit\n",
        "from datetime import datetime"
      ],
      "execution_count": 2,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "HKbLeJ1y0Umi",
        "outputId": "77f4acf0-e0cc-4196-b2b0-5fe77d70fd40",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "source": [
        "# Define a Python function\n",
        "def function_to_get_faster(x, y, b):\n",
        "  x = tf.matmul(x, y)\n",
        "  x = x + b\n",
        "  return x\n",
        "\n",
        "# Create a `Function` object that contains a graph\n",
        "a_function_that_uses_a_graph = tf.function(function_to_get_faster)\n",
        "\n",
        "# Make some tensors\n",
        "x1 = tf.constant([[1.0, 2.0]])     # > 1 row x 2 cols\n",
        "y1 = tf.constant([[2.0], [3.0]])    # > 2 rows x 1 col\n",
        "b1 = tf.constant(4.0)\n",
        "\n",
        "# It just works!\n",
        "a_function_that_uses_a_graph(x1, y1, b1).numpy()"
      ],
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([[12.]], dtype=float32)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 3
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "MT7U8ozok0gV"
      },
      "source": [
        "`tf.function`-ized functions are [Python callables]() that work the same as their Python equivalents.  They have a particular class (`python.eager.def_function.Function`), but to you they act just as the non-traced version.\n",
        "\n",
        "`tf.function` recursively traces any Python function it calls."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "rpz08iLplm9F",
        "outputId": "b660973b-edca-49da-cb52-d1fe6c1cb986",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "source": [
        "def inner_function(x, y, b):\n",
        "  x = tf.matmul(x, y)\n",
        "  x = x + b\n",
        "  return x\n",
        "\n",
        "# Use the decorator\n",
        "@tf.function\n",
        "def outer_function(x):\n",
        "  y = tf.constant([[2.0], [3.0]])\n",
        "  b = tf.constant(4.0)\n",
        "\n",
        "  return inner_function(x, y, b)\n",
        "\n",
        "# Note that the callable will create a graph that\n",
        "# includes inner_function() as well as outer_function()\n",
        "outer_function(tf.constant([[1.0, 2.0]])).numpy()"
      ],
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([[12.]], dtype=float32)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 4
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "P88fOr88qgCj"
      },
      "source": [
        "If you have used TensorFlow 1.x, you will notice that at no time did you need to define a `Placeholder` or `tf.Sesssion`."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "wfeKf0Nr1OEK"
      },
      "source": [
        "### Flow control and side effects\n",
        "\n",
        "Flow control and loops are converted to TensorFlow via `tf.autograph` by default.  Autograph uses a combination of methods, including standardizing loop constructs, unrolling, and [AST](https://docs.python.org/3/library/ast.html) manipulation.\n",
        "\n",
        ">>> AST = Abstract Syntax Trees = Collection of nodes based on the grammar of a programming lang (Python in this case) , i.e. it's what your input gets translated into at compilation\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "PFObpff1BMEb",
        "outputId": "653bc7d2-eddd-4ba9-d0f0-658a92a2e692",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "source": [
        "def my_function(x):\n",
        "  if tf.reduce_sum(x) <= 1:\n",
        "    return x * x\n",
        "  else:\n",
        "    return x-1\n",
        "\n",
        "a_function = tf.function(my_function)\n",
        "\n",
        "print(\"First branch, with graph:\", a_function(tf.constant(1.0)).numpy())\n",
        "print(\"Second branch, with graph:\", a_function(tf.constant([5.0, 5.0])).numpy())"
      ],
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "First branch, with graph: 1.0\n",
            "Second branch, with graph: [4. 4.]\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "hO4DBUNZBMwQ"
      },
      "source": [
        "You can directly call the Autograph conversion to see how Python is converted into TensorFlow ops.  This is, mostly, unreadable, but you can see the transformation."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "8x6RAqza1UWf",
        "outputId": "359f9e24-ae8c-4d5f-f1ad-abaa1cf7468d",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "source": [
        "# Don't read the output too carefully.\n",
        "print(tf.autograph.to_code(my_function))"
      ],
      "execution_count": 7,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "def tf__my_function(x):\n",
            "    with ag__.FunctionScope('my_function', 'fscope', ag__.ConversionOptions(recursive=True, user_requested=True, optional_features=(), internal_convert_user_code=True)) as fscope:\n",
            "        do_return = False\n",
            "        retval_ = ag__.UndefinedReturnValue()\n",
            "\n",
            "        def get_state():\n",
            "            return (retval_, do_return)\n",
            "\n",
            "        def set_state(vars_):\n",
            "            nonlocal retval_, do_return\n",
            "            (retval_, do_return) = vars_\n",
            "\n",
            "        def if_body():\n",
            "            nonlocal retval_, do_return\n",
            "            try:\n",
            "                do_return = True\n",
            "                retval_ = (ag__.ld(x) * ag__.ld(x))\n",
            "            except:\n",
            "                do_return = False\n",
            "                raise\n",
            "\n",
            "        def else_body():\n",
            "            nonlocal retval_, do_return\n",
            "            try:\n",
            "                do_return = True\n",
            "                retval_ = (ag__.ld(x) - 1)\n",
            "            except:\n",
            "                do_return = False\n",
            "                raise\n",
            "        ag__.if_stmt((ag__.converted_call(ag__.ld(tf).reduce_sum, (ag__.ld(x),), None, fscope) <= 1), if_body, else_body, get_state, set_state, ('retval_', 'do_return'), 2)\n",
            "        return fscope.ret(retval_, do_return)\n",
            "\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "GZ4Ieg6tBE6l"
      },
      "source": [
        "Autograph automatically converts `if-then` clauses, loops, `break`, `return`, `continue`, and more.\n",
        "\n",
        "Most of the time, Autograph will work without  special considerations.  However, there are some caveats, and the [tf.function guide](./function.ipynb) can help here, as well as the [complete autograph reference](https://github.com/tensorflow/tensorflow/blob/master/tensorflow/python/autograph/g3doc/reference/index.md)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "A6NHDp7vAKcJ"
      },
      "source": [
        "### Seeing the speed up\n",
        "\n",
        "Just wrapping a tensor-using function in `tf.function` does not automatically speed up your code.  For small functions called a few times on a single machine, the overhead of calling a graph or graph fragment may dominate runtime.  Also, if most of the computation was already happening on an accelerator, such as stacks of GPU-heavy convolutions, the graph speedup won't be large.\n",
        "\n",
        "For complicated computations, graphs can provide a significant speedup.  This is because graphs reduce the Python-to-device communication and perform some speedups.\n",
        "\n",
        "The speedup is most obvious when running many small layers, as in the example below:"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "jr7p1BBjauPK"
      },
      "source": [
        "# Create an oveerride model to classify pictures\n",
        "class SequentialModel(tf.keras.Model):\n",
        "  def __init__(self, **kwargs):\n",
        "    super(SequentialModel, self).__init__(**kwargs)\n",
        "    self.flatten = tf.keras.layers.Flatten(input_shape=(28, 28))\n",
        "    # Add a lot of small layers\n",
        "    num_layers = 100\n",
        "    self.my_layers = [tf.keras.layers.Dense(64, activation=\"relu\")\n",
        "                      for n in range(num_layers)]\n",
        "    self.dropout = tf.keras.layers.Dropout(0.2)\n",
        "    self.dense_2 = tf.keras.layers.Dense(10)\n",
        "\n",
        "  def call(self, x):\n",
        "    x = self.flatten(x)\n",
        "    for layer in self.my_layers: # 100 times\n",
        "      x = layer(x)\n",
        "    x = self.dropout(x)\n",
        "    x = self.dense_2(x)\n",
        "    return x"
      ],
      "execution_count": 8,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ms2yJyAnUYxK"
      },
      "source": [
        "input_data = tf.random.uniform([20, 28, 28])"
      ],
      "execution_count": 9,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "zbNndv-0BeO4",
        "outputId": "f4216080-4362-45ed-fc64-8df1463a237b",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "source": [
        "eager_model = SequentialModel()\n",
        "\n",
        "# Don't count the time for the initial build.\n",
        "eager_model(input_data)\n",
        "print(\"Eager time:\", timeit.timeit(lambda: eager_model(input_data), number=100))"
      ],
      "execution_count": 14,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Eager time: 2.07617378000009\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "61hh4IDfPNXe",
        "outputId": "2e68bb63-6842-4001-ab5d-43d07d61f007",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "source": [
        "# Wrap the call method in a `tf.function`\n",
        "graph_model = SequentialModel()\n",
        "graph_model.call = tf.function(graph_model.call)\n",
        "\n",
        "# Don't count the time for the initial build and trace.\n",
        "graph_model(input_data)\n",
        "print(\"Graph time:\", timeit.timeit(lambda: graph_model(input_data), number=100))"
      ],
      "execution_count": 15,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Graph time: 0.2277033029999984\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "sIpc_jfjEZEg"
      },
      "source": [
        "### Polymorphic functions\n",
        "\n",
        "When you trace a function, you create a `Function` object that is **polymorphic**.  A polymorphic function is a Python callable that encapsulates several concrete function graphs behind one API.\n",
        "\n",
        "You can use this `Function` on all different kinds of `dtypes` and shapes.  Each time you invoke it with a new argument signature, the original function gets re-traced with the new arguments.  The `Function` then stores the `tf.Graph` corresponding to that trace in a `concrete_function`.  If the function has already been traced with that kind of argument, you just get your pre-traced graph.\n",
        "\n",
        "Conceptually, then:\n",
        "* A **`tf.Graph`** is the raw, portable data structure describing a computation\n",
        "* A **`Function`** is a caching, tracing, dispatcher over ConcreteFunctions\n",
        "* A **`ConcreteFunction`** is an eager-compatible wrapper around a graph that lets you execute the graph from Python\n",
        "\n",
        "\n",
        "\n",
        ">>> Tracing: Calling a python function with tf.function and hence \"recording\" its tensorflow operations in a graph. I.e. after tracing youhave the above seen autograph conversion. (It is only done once, when first executing it)\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "kNGuLnjK1c5U"
      },
      "source": [
        "### Inspecting polymorphic functions\n",
        "\n",
        "You can inspect `a_function`, which is the result of calling `tf.function` on the Python function `my_function`.  In this example, calling `a_function` with three kinds of arguments results in three different concrete functions.\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "7heuYuwn2edE",
        "outputId": "3ba1a7cd-7619-456d-c01d-c9feab25026a",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "source": [
        "print(a_function)\n",
        "\n",
        "print(\"Calling a `Function`:\")\n",
        "print(\"Int:\", a_function(tf.constant(2)))\n",
        "print(\"Float:\", a_function(tf.constant(2.0)))\n",
        "print(\"Rank-1 tensor of floats\", a_function(tf.constant([2.0, 2.0, 2.0])))"
      ],
      "execution_count": 16,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "<tensorflow.python.eager.def_function.Function object at 0x7fb90fe4eef0>\n",
            "Calling a `Function`:\n",
            "Int: tf.Tensor(1, shape=(), dtype=int32)\n",
            "Float: tf.Tensor(1.0, shape=(), dtype=float32)\n",
            "Rank-1 tensor of floats tf.Tensor([1. 1. 1.], shape=(3,), dtype=float32)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "s1c8db0cCW2k",
        "outputId": "aac10bee-1089-4604-9470-cc1011115bbc",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "source": [
        "# Get the concrete function that works on floats\n",
        "print(\"Inspecting concrete functions\")\n",
        "print(\"Concrete function for float:\")\n",
        "print(a_function.get_concrete_function(tf.TensorSpec(shape=[], dtype=tf.float32)))\n",
        "print(\"Concrete function for tensor of floats:\")\n",
        "print(a_function.get_concrete_function(tf.constant([2.0, 2.0, 2.0])))\n"
      ],
      "execution_count": 17,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Inspecting concrete functions\n",
            "Concrete function for float:\n",
            "ConcreteFunction my_function(x)\n",
            "  Args:\n",
            "    x: float32 Tensor, shape=()\n",
            "  Returns:\n",
            "    float32 Tensor, shape=()\n",
            "Concrete function for tensor of floats:\n",
            "ConcreteFunction my_function(x)\n",
            "  Args:\n",
            "    x: float32 Tensor, shape=(3,)\n",
            "  Returns:\n",
            "    float32 Tensor, shape=(3,)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "JLTNuv_CCZXK",
        "outputId": "6be3354f-58ed-4527-b56b-cc62970a36bf",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "source": [
        "# Concrete functions are callable\n",
        "# Note: You won't normally do this, but instead just call the containing `Function`\n",
        "cf = a_function.get_concrete_function(tf.constant(2))\n",
        "print(\"Directly calling a concrete function:\", cf(tf.constant(2)))"
      ],
      "execution_count": 18,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Directly calling a concrete function: tf.Tensor(1, shape=(), dtype=int32)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "PTHNiHLXH9es"
      },
      "source": [
        "In this example, you are seeing pretty far into the stack.  Unless you are specifically managing tracing, you will not normally need to call concrete functions directly as shown here."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "V11zkxU22XeD"
      },
      "source": [
        "## Reverting to eager execution\n",
        "\n",
        "You may find yourself looking at long stack traces, specially ones that refer to `tf.Graph` or `with tf.Graph().as_default()`.  This means you are likely running in a graph context.  Core functions in TensorFlow use graph contexts, such as Keras's `model.fit()`.\n",
        "\n",
        "It is often much easier to debug eager execution.  Stack traces should be relatively short and easy to comprehend.\n",
        "\n",
        "In situations where the graph makes debugging tricky, you can revert to using eager execution to debug. \n",
        "\n",
        "Here are ways you can make sure you are running eagerly:\n",
        "\n",
        "* Call models and layers directly as callables\n",
        "\n",
        "* When using Keras compile/fit, at compile time use **`model.compile(run_eagerly=True)`**\n",
        "\n",
        "* Set global execution mode via  **`tf.config.run_functions_eagerly(True)`**\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "QF6mxah8mqth"
      },
      "source": [
        ">>> With Eager execution, TensorFlow calculates the values of tensors as they occur in your code.\r\n",
        ">>> Without Graphs are created\r\n",
        "\r\n",
        "\r\n",
        ">>> Hence you can turn eager into graphs and vice-versa"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "iTHvdQfRICJb"
      },
      "source": [
        "### Using `run_eagerly=True`"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "kqzBV2rSzvpC"
      },
      "source": [
        "# Define an identity layer with an eager side effect\n",
        "class EagerLayer(tf.keras.layers.Layer):\n",
        "  def __init__(self, **kwargs):\n",
        "    super(EagerLayer, self).__init__(**kwargs)\n",
        "    # Do some kind of initialization here\n",
        "\n",
        "  def call(self, inputs):\n",
        "    print(\"\\nCurrently running eagerly\", str(datetime.now()))\n",
        "    return inputs"
      ],
      "execution_count": 21,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "5DFvc9ySr7t3"
      },
      "source": [
        "# Create an override model to classify pictures, adding the custom layer\n",
        "class SequentialModel(tf.keras.Model):\n",
        "  def __init__(self):\n",
        "    super(SequentialModel, self).__init__()\n",
        "    self.flatten = tf.keras.layers.Flatten(input_shape=(28, 28))\n",
        "    self.dense_1 = tf.keras.layers.Dense(128, activation=\"relu\")\n",
        "    self.dropout = tf.keras.layers.Dropout(0.2)\n",
        "    self.dense_2 = tf.keras.layers.Dense(10)\n",
        "    self.eager = EagerLayer()\n",
        "\n",
        "  def call(self, x):\n",
        "    x = self.flatten(x)\n",
        "    x = self.dense_1(x)\n",
        "    x = self.dropout(x)\n",
        "    x = self.dense_2(x)\n",
        "    return self.eager(x)\n",
        "\n",
        "# Create an instance of this model\n",
        "model = SequentialModel()\n",
        "\n",
        "# Generate some nonsense pictures and labels\n",
        "input_data = tf.random.uniform([60, 28, 28])\n",
        "labels = tf.random.uniform([60])\n",
        "\n",
        "loss_fn = tf.keras.losses.SparseCategoricalCrossentropy(from_logits=True)"
      ],
      "execution_count": 22,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "U3-hcwmpI3Sv"
      },
      "source": [
        "First, compile the model without eager. Note that the model is not traced; despite its name, `compile` only sets up loss functions, optimization, and other training parameters."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "w2GdwhB_KQlw"
      },
      "source": [
        "model.compile(run_eagerly=False, loss=loss_fn)"
      ],
      "execution_count": 23,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "WLMXk1uxKQ44"
      },
      "source": [
        "Now, call `fit` and see that the function is traced (twice) and then the eager effect never runs again."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "1yBI1Qd-n8JG"
      },
      "source": [
        ">>> The Python print statement gets removed once traced and is not part of the graph --- This is what makes it cross-device compatible (i.e. you can use tensorflow for js applications w/o any python)\r\n",
        "\r\n",
        "\r\n",
        "It is traced twice (i.e. printed twice before starting, because they test wether you have made a mistake such as initializing a value in the function (this value would not be initialized if turned into the computation graph hence they throw an error) --- Check the TF YT Video Functions not sessions for a deeper explanation"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "VCoLlZDythZ8",
        "outputId": "5a31e011-ee5a-4a79-a14f-c47b29989eec",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "source": [
        "model.fit(input_data, labels, epochs=3)"
      ],
      "execution_count": 24,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Epoch 1/3\n",
            "\n",
            "Currently running eagerly 2021-01-20 11:46:55.851440\n",
            "\n",
            "Currently running eagerly 2021-01-20 11:46:56.023096\n",
            "2/2 [==============================] - 1s 8ms/step - loss: 0.8666\n",
            "Epoch 2/3\n",
            "2/2 [==============================] - 0s 7ms/step - loss: 6.2151e-04\n",
            "Epoch 3/3\n",
            "2/2 [==============================] - 0s 5ms/step - loss: 4.1042e-04\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<tensorflow.python.keras.callbacks.History at 0x7fb90a5145c0>"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 24
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "jOk6feLOK1pR"
      },
      "source": [
        "If you run even a single epoch in eager, however, you can see the eager side effect twice."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "MGIYwrKpK06e",
        "outputId": "b43b9fec-5d94-483d-9a19-d28582a58a10",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "source": [
        "print(\"Running eagerly\")\n",
        "# When compiling the model, set it to run eagerly\n",
        "model.compile(run_eagerly=True, loss=loss_fn)\n",
        "\n",
        "model.fit(input_data, labels, epochs=1)\n"
      ],
      "execution_count": 25,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Running eagerly\n",
            "\n",
            "Currently running eagerly 2021-01-20 11:47:41.222148\n",
            "1/2 [==============>...............] - ETA: 0s - loss: 5.7038e-04\n",
            "Currently running eagerly 2021-01-20 11:47:41.264834\n",
            "2/2 [==============================] - 0s 18ms/step - loss: 3.9293e-04\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<tensorflow.python.keras.callbacks.History at 0x7fb90879f3c8>"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 25
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "qwq_cnc8Lwf8"
      },
      "source": [
        "### Using `run_functions_eagerly`\n",
        "You can also globally set everything to run eagerly.  This is a switch that bypasses the polymorphic function's traced functions and calls the original function directly.  You can use this for debugging."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "oFSxRtcptYpe",
        "outputId": "3ea2c504-986b-4efc-add1-45282229ca73",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "source": [
        "# Now, globally set everything to run eagerly\n",
        "tf.config.run_functions_eagerly(True) # True by default!\n",
        "print(\"Run all functions eagerly.\")\n",
        "\n",
        "# Create a polymorphic function\n",
        "polymorphic_function = tf.function(model)\n",
        "\n",
        "print(\"Tracing\")\n",
        "# This does, in fact, trace the function\n",
        "print(polymorphic_function.get_concrete_function(input_data))\n",
        "\n",
        "print(\"\\nCalling twice eagerly\")\n",
        "# When you run the function again, you will see the side effect\n",
        "# twice, as the function is running eagerly.\n",
        "result = polymorphic_function(input_data)\n",
        "result = polymorphic_function(input_data)"
      ],
      "execution_count": 28,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Run all functions eagerly.\n",
            "Tracing\n",
            "\n",
            "Currently running eagerly 2021-01-20 11:51:55.749741\n",
            "ConcreteFunction function(self)\n",
            "  Args:\n",
            "    self: float32 Tensor, shape=(60, 28, 28)\n",
            "  Returns:\n",
            "    float32 Tensor, shape=(60, 10)\n",
            "\n",
            "Calling twice eagerly\n",
            "\n",
            "Currently running eagerly 2021-01-20 11:51:55.757556\n",
            "\n",
            "Currently running eagerly 2021-01-20 11:51:55.760335\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "pD-AQxEhua4E",
        "outputId": "8717a0e4-c4f5-4674-9c94-b6ca3805dbaf",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "source": [
        "# Don't forget to set it back when you are done\n",
        "# tf.config.experimental_run_functions_eagerly(False) >>> Deprecated\n",
        "\n",
        "tf.config.run_functions_eagerly(False)\n",
        "# Check value with:\n",
        "tf.config.functions_run_eagerly()"
      ],
      "execution_count": 36,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "False"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 36
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "sm0bNFp8PX53"
      },
      "source": [
        "## Tracing and performance\n",
        "\n",
        "Tracing costs some overhead. Although tracing small functions is quick, large models can take noticeable wall-clock time to trace.  This investment is usually quickly paid back with a  performance boost, but it's important to be aware that the first few epochs of any large model training can be slower due to tracing.\n",
        "\n",
        "No matter how large your model, you want to avoid tracing frequently. This [section of the tf.function guide](function.ipynb#when_to_retrace) discusses how to set input specifications and use tensor arguments to avoid retracing.  If you find you are getting unusually poor performance, it's good to check to see if you are retracing accidentally.\n",
        "\n",
        "You can add an eager-only side effect (such as printing a Python argument) so you can see when the function is being traced.  Here, you see extra retracing because new Python arguments always trigger retracing.\n",
        "\n",
        "\n",
        ">>> Retracing happens if you e.g. call a tf function inputting a python variable (e.g. epoch) that changes all the time outside of tf function; It should throw a warning if retracing happens"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "jsGQ4GQAP2Ve",
        "outputId": "ede71d26-179a-4392-b675-83c8f8c4d94d",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "source": [
        "# Use @tf.function decorator\n",
        "@tf.function\n",
        "def a_function_with_python_side_effect(x):\n",
        "  print(\"Tracing!\")  # This eager\n",
        "  return x * x + tf.constant(2)\n",
        "\n",
        "# This is traced the first time\n",
        "print(a_function_with_python_side_effect(tf.constant(2)))\n",
        "# The second time through, you won't see the side effect\n",
        "print(a_function_with_python_side_effect(tf.constant(3)))\n",
        "\n",
        "# This retraces each time the Python argument changes,\n",
        "# as a Python argument could be an epoch count or other\n",
        "# hyperparameter\n",
        "print(a_function_with_python_side_effect(2))\n",
        "print(a_function_with_python_side_effect(3))\n"
      ],
      "execution_count": 39,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Tracing!\n",
            "tf.Tensor(6, shape=(), dtype=int32)\n",
            "tf.Tensor(11, shape=(), dtype=int32)\n",
            "Tracing!\n",
            "tf.Tensor(6, shape=(), dtype=int32)\n",
            "Tracing!\n",
            "tf.Tensor(11, shape=(), dtype=int32)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "D1kbr5ocpS6R"
      },
      "source": [
        "## Next steps\n",
        "\n",
        "You can read a more in-depth discussion at both the `tf.function` API reference page and at the [guide](./function.ipynb)."
      ]
    }
  ]
}